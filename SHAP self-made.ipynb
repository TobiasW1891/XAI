{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a872613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/users/t_wand01/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow import keras \n",
    "import random\n",
    "import shap\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfcc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is a fairly simple linear Model which is binarized for the Neural Net (second example)\n",
    "\n",
    "xsize = 1000\n",
    "X = np.random.rand(xsize,10)\n",
    "# only X[:,0], X[:,4], X[:,1] and X[:,2] are relevant and their relevance is in that order\n",
    "y = 5.*X[:,0] - 1. * X[:,1] - 0.5*X[:,2] - 4.*X[:,4] + 0.2*np.random.normal(size=xsize) \n",
    "yNN = (y> np.mean(y))*1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94d50ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57587524 0.56480405 0.6171897  0.91577584 0.87570756 0.9586376\n",
      " 0.56066034 0.65012475 0.76804022 0.02647688]\n",
      "-1.2938901938360623\n"
     ]
    }
   ],
   "source": [
    "print(X[1,:])\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fd5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08393fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.03210046e+00 -1.00166615e+00 -4.82469916e-01  1.88041036e-02\n",
      " -3.99680430e+00 -4.57412719e-03  9.57479982e-04 -1.09429971e-02\n",
      "  2.18354439e-02  4.46516136e-02]\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_)  # Seems alright!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff4bf7",
   "metadata": {},
   "source": [
    "## Let's try to code SHAP for ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7305f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = X.shape[1] # Number of Features\n",
    "n = 100 # Sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e43bf",
   "metadata": {},
   "source": [
    "We wish to sample from an extreme Beta-Distribution so that we get either very few or very many features. The first case shows the isolatd effect of a feature, the latter the interaction of a feature with all other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d8841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = np.random.beta(0.2, 0.2,1000)\n",
    "sample = sample*X.shape[1]+1\n",
    "sample = np.floor(sample).astype(int)\n",
    "plt.hist(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c05cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 7]\n",
      "[3 0 7]\n",
      "[10  1  2 10  4  5  6 10  8  9]\n"
     ]
    }
   ],
   "source": [
    "sel = np.random.choice(np.arange(p), size=3, replace=False)\n",
    "print(sel)\n",
    "r = np.arange(X.shape[1])\n",
    "print(r[sel])\n",
    "r[sel] = X.shape[1]\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38fa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChooseK(P):# P is integer of Feature number\n",
    "    K =np.random.beta(0.2, 0.2,1)\n",
    "    K = int(P*K+1)\n",
    "    if K==P+1: # some degenerate cases\n",
    "        K = K-1\n",
    "    return(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c37e0274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChooseK(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24238ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 10.0\n",
      "[ 6.  1.  1. ...  1. 10. 10.]\n"
     ]
    }
   ],
   "source": [
    "ks = np.empty(5000)\n",
    "for ll in range(5000):\n",
    "    ks[ll] =ChooseK(X.shape[1])\n",
    "plt.hist(ks)\n",
    "plt.show()\n",
    "print(min(ks),max(ks))\n",
    "print(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1853d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SwapFeatures(i,m,j,k):\n",
    "    # take instance x_i, exchange k of its features randomly with the features of x_m including the jth Feature\n",
    "    output = X[i,:].copy()\n",
    "    \n",
    "    if k == 1: # only change jth Feature\n",
    "        output[j] = X[m,j].copy()\n",
    "    \n",
    "    else:\n",
    "        Selection = np.random.choice(np.arange(X.shape[1]), size=k, replace=False)\n",
    "        while (np.sum(Selection==j) ==0): # Make sure that j is included in selection\n",
    "            Selection = np.random.choice(np.arange(X.shape[1]), size=k, replace=False)\n",
    "        \n",
    "        output[Selection] = X[m,Selection].copy()\n",
    "    \n",
    "    return(output)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02cb8068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6548584  0.62452711 0.05623634 0.64520465 0.76198791 0.50511374\n",
      "  0.62436509 0.15458074 0.77137547 0.50833434]\n",
      " [0.57587524 0.56480405 0.6171897  0.91577584 0.87570756 0.9586376\n",
      "  0.56066034 0.65012475 0.76804022 0.02647688]\n",
      " [0.56441316 0.53510248 0.4902244  0.82769487 0.02714765 0.49926048\n",
      "  0.56489094 0.66447874 0.87025362 0.42430187]\n",
      " [0.26356092 0.91702752 0.90971355 0.43094405 0.31963381 0.11386571\n",
      "  0.64526955 0.48146997 0.22782705 0.75028685]]\n",
      "[0.26356092 0.53510248 0.4902244  0.82769487 0.31963381 0.49926048\n",
      " 0.56489094 0.66447874 0.87025362 0.42430187]\n"
     ]
    }
   ],
   "source": [
    "print(X[np.arange(4),:])\n",
    "print(SwapFeatures(2,3,0,2)) # the instance X[2,:] gets 2 features from X[3,:], including X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a55e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare(x_j, x_noj, Model):\n",
    "    return(Model.predict(x_j.reshape(1, -1)) - Model.predict(x_noj.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb301bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.47943852])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(np.arange(X.shape[1]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b187f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcShap(X,i,j,M,Model):\n",
    "    # Calculate Shap values for DataSet X for ith instance and jth feature with M iterations for AI-Model \"Model\"\n",
    "    M_iter = 0 # iteration index\n",
    "    SHAPValues = np.empty(M)\n",
    "    \n",
    "    while M_iter<M:\n",
    "        m = np.random.randint(X.shape[0]) # random instance to \"mix\" x_i with\n",
    "    \n",
    "        if m!=i:\n",
    "            k = ChooseK(X.shape[1])\n",
    "            \n",
    "            x_dummy_noj = SwapFeatures(i,m,j,k) # sample from random other instance\n",
    "            x_dummy_j = x_dummy_noj.copy()\n",
    "            x_dummy_j[j] = X[i,j].copy()  # compare with j and without j\n",
    "        \n",
    "            SHAPValues[M_iter] = Compare(x_dummy_j,x_dummy_noj, Model=reg)\n",
    "        \n",
    "            M_iter = M_iter+1\n",
    "            \n",
    "    return(np.mean(SHAPValues))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f7dba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureImportance(X,j,M1,M2,Model):\n",
    "    # Calculate Feature Importancec over M1 instances for j'th Feature of Data Set X,\n",
    "    #   compare each instance M2 times and evaluate via Model\n",
    "    \n",
    "    Output = np.empty(M1)\n",
    "    \n",
    "    for m1 in range(M1):\n",
    "        i = np.random.randint(X.shape[0])\n",
    "        Output[m1] = np.abs(CalcShap(X,i,j,M2,Model))\n",
    "        \n",
    "    return(np.mean(Output))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9743ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the ith instance\n",
    "SHAPValues_i = np.empty(X.shape[1])\n",
    "for index in range(X.shape[1]):\n",
    "    SHAPValues_i[index] = CalcShap(X, i=0, j = index, M = 1000, Model=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f9d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3532737268801\n",
      "1 0.2531441569426944\n",
      "2 0.11012463357821706\n",
      "3 0.004514833853148605\n",
      "4 1.0495183491088091\n",
      "5 0.0010916906673497755\n",
      "6 0.00026269925065219933\n",
      "7 0.0029420112630933457\n",
      "8 0.00582315608919601\n",
      "9 0.010528751904932023\n"
     ]
    }
   ],
   "source": [
    "# For the entire Data Set\n",
    "SHAP_Importance = np.empty(X.shape[1])\n",
    "for Jf in range(X.shape[1]):\n",
    "    SHAP_Importance[Jf] = FeatureImportance(X,Jf,100,100,reg)\n",
    "    print(Jf, SHAP_Importance[Jf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e5564",
   "metadata": {},
   "source": [
    "## Sanity Checks\n",
    "\n",
    "We can reproduce the coefficients of the linear model with the SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35f0a087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.75278268e-01, -1.16324537e-01,  2.11584802e-01,  2.31647856e-03,\n",
       "       -1.04800528e+00, -2.37438577e-05,  1.07575805e-04,  3.62386726e-03,\n",
       "        6.61150813e-03,  2.91681876e-04])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHAPValues_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27585c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.901988476789127\n",
      "-1.0722274778425613\n",
      "-0.48287180898832904\n",
      "0.01827811388515518\n",
      "-4.007197834126097\n",
      "-0.003801389287367128\n",
      "0.0008546526826318826\n",
      "-0.010714800350906472\n",
      "0.023687017183605285\n",
      "0.02118369385586507\n"
     ]
    }
   ],
   "source": [
    "for index in range(X.shape[1]):\n",
    "    print(SHAPValues_i[index]/ (X[0,index]-np.mean(X[:,index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de224f0e",
   "metadata": {},
   "source": [
    "Very close to the real linear coefficients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f567913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35327373e+00, 2.53144157e-01, 1.10124634e-01, 4.51483385e-03,\n",
       "       1.04951835e+00, 1.09169067e-03, 2.62699251e-04, 2.94201126e-03,\n",
       "       5.82315609e-03, 1.05287519e-02])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHAP_Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0205a737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.344577866699006\n",
      "1.0127422679090574\n",
      "0.4365253029014579\n",
      "0.018080097974481298\n",
      "4.17753492358219\n",
      "0.004427809439256544\n",
      "0.0010453134913014374\n",
      "0.01184204482856433\n",
      "0.022594222279287385\n",
      "0.041368528328397845\n"
     ]
    }
   ],
   "source": [
    "for a in range(X.shape[1]):\n",
    "    print(SHAP_Importance[a]/np.mean(np.abs(X[:,a]-np.mean(X[:,a]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76454e2",
   "metadata": {},
   "source": [
    "##### These are reasonably close to the absolute values of the linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84741282",
   "metadata": {},
   "source": [
    "## Now with a Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ec7128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/users/t_wand01/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 0s 1ms/sample - loss: 0.6874 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 68us/sample - loss: 0.6835 - acc: 0.5600\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 58us/sample - loss: 0.6817 - acc: 0.5800\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.6780 - acc: 0.6200\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 55us/sample - loss: 0.6756 - acc: 0.6400\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 59us/sample - loss: 0.6725 - acc: 0.6400\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 68us/sample - loss: 0.6699 - acc: 0.6400\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 56us/sample - loss: 0.6667 - acc: 0.6800\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 55us/sample - loss: 0.6637 - acc: 0.6800\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 56us/sample - loss: 0.6605 - acc: 0.6600\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 57us/sample - loss: 0.6573 - acc: 0.6800\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 55us/sample - loss: 0.6542 - acc: 0.6800\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.6512 - acc: 0.6800\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 54us/sample - loss: 0.6483 - acc: 0.7000\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 60us/sample - loss: 0.6455 - acc: 0.7000\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 59us/sample - loss: 0.6430 - acc: 0.7400\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 56us/sample - loss: 0.6410 - acc: 0.7400\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 57us/sample - loss: 0.6377 - acc: 0.7400\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 56us/sample - loss: 0.6355 - acc: 0.7400\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 58us/sample - loss: 0.6323 - acc: 0.7400\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 56us/sample - loss: 0.6308 - acc: 0.7400\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.6276 - acc: 0.7400\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.6276 - acc: 0.7400\n",
      "Epoch 24/50\n",
      "10/50 [=====>........................] - ETA: 0s - loss: 0.6080 - acc: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 15:49:45.944002: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2021-10-26 15:49:45.947111: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz\n",
      "2021-10-26 15:49:45.947628: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3605400 executing computations on platform Host. Devices:\n",
      "2021-10-26 15:49:45.947638: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2021-10-26 15:49:45.968223: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 71us/sample - loss: 0.6235 - acc: 0.7600\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.6209 - acc: 0.7600\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.6181 - acc: 0.7600\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 50us/sample - loss: 0.6159 - acc: 0.7600\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.6137 - acc: 0.7600\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 57us/sample - loss: 0.6107 - acc: 0.7600\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 54us/sample - loss: 0.6084 - acc: 0.7600\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.6060 - acc: 0.7600\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.6035 - acc: 0.7600\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 57us/sample - loss: 0.6007 - acc: 0.7600\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.5981 - acc: 0.7600\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.5960 - acc: 0.7800\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 50us/sample - loss: 0.5925 - acc: 0.7800\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 55us/sample - loss: 0.5897 - acc: 0.7800\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 56us/sample - loss: 0.5879 - acc: 0.7800\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 49us/sample - loss: 0.5839 - acc: 0.7800\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 49us/sample - loss: 0.5825 - acc: 0.7800\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 48us/sample - loss: 0.5783 - acc: 0.7800\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.5746 - acc: 0.7800\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 50us/sample - loss: 0.5712 - acc: 0.7800\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.5676 - acc: 0.7800\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 49us/sample - loss: 0.5647 - acc: 0.7800\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 52us/sample - loss: 0.5608 - acc: 0.8000\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 62us/sample - loss: 0.5588 - acc: 0.8200\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 58us/sample - loss: 0.5542 - acc: 0.8200\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 54us/sample - loss: 0.5507 - acc: 0.8200\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 53us/sample - loss: 0.5470 - acc: 0.8200\n",
      "950/950 [==============================] - 0s 21us/sample - loss: 0.5663 - acc: 0.7453\n",
      "Accuracy: 74.53\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "NN = keras.models.Sequential()\n",
    "NN.add(keras.layers.Dense(12, input_dim=X.shape[1], activation='relu'))\n",
    "NN.add(keras.layers.Dense(8, activation='relu'))\n",
    "NN.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "NN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "NN.fit(X[0:50,:],yNN[0:50], epochs=50, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = NN.evaluate(X[50:,:], yNN[50:])\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3e6775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6289245 ]\n",
      " [0.36166906]\n",
      " [0.75957596]\n",
      " [0.6108831 ]\n",
      " [0.3714633 ]\n",
      " [0.7427145 ]\n",
      " [0.29408666]\n",
      " [0.40903446]\n",
      " [0.36803323]\n",
      " [0.5293021 ]\n",
      " [0.39614862]\n",
      " [0.38034365]\n",
      " [0.35106367]\n",
      " [0.53203297]\n",
      " [0.33880973]\n",
      " [0.5608228 ]\n",
      " [0.6380323 ]\n",
      " [0.47932437]\n",
      " [0.27983335]\n",
      " [0.6843995 ]]\n",
      "[1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(NN.predict(X[40:60,:]))\n",
    "print(yNN[40:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8de285b",
   "metadata": {},
   "source": [
    "#### Now with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16d75621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1685723149730352\n",
      "1 0.22992151455699272\n",
      "2 0.12826896261372864\n",
      "3 0.004392042141537076\n",
      "4 0.9537738997195153\n",
      "5 0.0011022159449261913\n",
      "6 0.00023558360151216534\n",
      "7 0.002578695152316603\n",
      "8 0.005923354275094959\n",
      "9 0.013190511162871033\n"
     ]
    }
   ],
   "source": [
    "SHAP_Importance_NN = np.empty(X.shape[1])\n",
    "for Jf in range(X.shape[1]):\n",
    "    SHAP_Importance_NN[Jf] = FeatureImportance(X,Jf,100,100,NN)\n",
    "    print(Jf, SHAP_Importance_NN[Jf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc86795",
   "metadata": {},
   "source": [
    "Ranking makes sense! Importances are similar to the linear Regression case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa540e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
